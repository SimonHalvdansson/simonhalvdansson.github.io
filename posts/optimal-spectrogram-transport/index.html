<!DOCTYPE html>
<html>
<head>
	<title>Optimal spectrogram transport</title>

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="theme-color" content="#FBEDEA" />

	<link rel="shortcut icon" type="image/x-icon"  href="../../favicon.ico?">
	<link rel="apple-touch-icon" href="../../apple-touch-icon.png">

	<link rel="stylesheet" href="style.css">

	<script>
	window.MathJax = {
	tex: {
		inlineMath: [['$', '$'], ['\\(', '\\)']]
	}
	};
	</script>

	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

	<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;500;600;700&display=swap" rel="stylesheet">

	<link rel="stylesheet" href="../atom-one-dark.min.css">
	<script src="../highlight.min.js"></script>

	<script>hljs.highlightAll();</script>

</head>
<body>
	<div class="blog centering" id="back_container">
		<a href="../index.html" class="back"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="14" fill="currentColor" class="bi bi-caret-left" viewBox="0 0 22 18">
			<path fill-rule="evenodd" clip-rule="evenodd" d="M14.0303 7.46967C14.3232 7.76256 14.3232 8.23744 14.0303 8.53033L10.5607 12L14.0303 15.4697C14.3232 15.7626 14.3232 16.2374 14.0303 16.5303C13.7374 16.8232 13.2626 16.8232 12.9697 16.5303L8.96967 12.5303C8.67678 12.2374 8.67678 11.7626 8.96967 11.4697L12.9697 7.46967C13.2626 7.17678 13.7374 7.17678 14.0303 7.46967Z"/>
		  </svg>All posts</a>
	</div>

	<section class="blog centering post">
		<h1>Notions of time-aware signal distance functions - optimal spectrogram transport</h1>
		<div class="subtitle monospace">By Simon Halvdansson&nbsp;|&nbsp;Sep. 2025</div>

		<hr class="squiggly-line"/>

		<p>
			Determining if two vectors are near each other is generally a straightforward problem - Euclidean distance or cosine similarity are standard solutions. In this post, we are interested in the special case where the vector indices indicate time, i.e., vectors which represent time series data or signals. There are specialized metrics available for this class of vectors but as we will see their preference for translations over modulations poses an issue for signals which exhibit some form of <i>time-frequency</i> structure or time-warying oscillations such as those related to audio, radar, EEG, seismic activity or vibrations.
		</p>

		<p>
			We will make the case that an appropriate solution is <i>optimal transport distance between spectrograms</i> through examples where other methods fail.
		</p>

		<div class="figure_container_small" id="main_fig">
			<a data-fancybox="gallery0" href="media/07_sinusoid_distance.gif">
				<img class="figure" src="media/07_sinusoid_distance.gif"></img>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Euclidean $\ell^2$, dynamic time warping and optimal spectrogram distances for a family of sinusoids of increasing frequency.
		</div>

		<p>
			We will go over the problems with naive Euclidean $\ell^2$ distance, the standard solution which is called <i>dynamic time warping (DTW)</i>, why it does not work when frequency changes are involved, and one way to solve it using the tools from optimal transport applied to spectrograms.
		</p>

		<hr class="squiggly-line"/>
		<h2>Why look at distances between signals?</h2>

		<p>
			The standard motivation for looking at distances between signals is to perform some sort of clustering/classification/anomaly detection task. We could get around the need for a distance function by first applying some form of encoding and computing a standard distance in a latent space. In a machine learning setting, this latent representation would be the output of some neural network like in <a target="_blank" href="https://ai.meta.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/">wav2vec</a>.
		</p>

		<div class="figure_container_small"  style="padding: 0;">
			<a data-fancybox="gallery1" href="media/wav2vec.jpg">
				<img class="figure" src="media/wav2vec.jpg"></img>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> 2D PCA wav2vec 2.0 embeddings for speech audio from different languages, from the wav2vec 2.0 <a target="_blank" href="https://ai.meta.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/">blog post</a>.
		</div>
		
		<p>
			There are obvious interpretability benefits to a distance function which works directly on the signal - it should be considerably more explainable than a neural encoding. A distance function which makes sense for the domain of the data also ideally should improve the inductive bias of the model and help reduce complexity of a neural network working on it. 
		</p>

		<hr class="squiggly-line"/>
		<h2>The problem with Euclidean distance</h2>

		<p>
			From a time-frequency perspective there are two insurmountable problems with looking at Euclidean distance between signals (one in time, one in frequency), both best explained by examples. Consider first the case of two signals, each with a well localized peak at slightly different locations. A (low-dimensional) one would be $x_1 = (0,0,0,1,0)$ and $x_2 = (0,0,1,0,0)$. Clearly the Euclidean distance between these two vectors is $2$ but they are considerably closer than $(1,0,0,0,0)$ and $(0,0,0,0,1)$ as any sane person should conclude. Note that this is not necessarily the case if the indices do not have some temporal meaning.
		</p>

		<p>
			The other problem with Euclidean distance is a direct corollary of <a href="https://en.wikipedia.org/wiki/Parseval%27s_identity" target="_blank">Parseval's identity</a> and boils down to pure tone sinusoids being orthogonal. This means that a 101 Hz pure tone and a 200 Hz pure tone both have the same distance to a 100 Hz pure tone. Mathematically,
		</p>

		<div class="equation">
			$\big\langle \sin(n\,\cdot), \sin(m\,\cdot)\big\rangle = \begin{cases} 1\qquad m=n,\\ 0 \qquad m \neq n \end{cases}$
		</div>

		<p>
			for integers $m, n$. This is what is illustrated in the <a href="#main_fig">figure</a> at the start of the post.
		</p>

		<hr class="squiggly-line"/>
		<h2>Dynamic time warping (DTW)</h2>
		<p>
			Romain Tavenard wrote an excellent <a href="https://rtavenar.github.io/blog/dtw.html" target="_blank">overview</a> of DTW which I will refer to for details. On a high level, the dynamic time warping distance between two signals $x_1$ and $x_2$ is realized by minimizing the Euclidean distance between $x_1$ and $x_2$ over all non-decreasing index permutations. The figure below illustrates the concept nicely.
		</p>
		<div class="figure_container">
			<a data-fancybox="gallery2" href="media/09_dtw_alignment.mp4">
				<video class="figure" src="media/09_dtw_alignment.mp4" autoplay muted playsinline loop preload="metadata"></video>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> The DTW distance between two signals illustrated by the permutation map.
		</div>
		
		<p>
			This is the "standard" smart solution but as we will see in the <a href="#examples">examples</a> below, rearranging the indices does not allow us to align signals with close frequencies.
		</p>

		<hr class="squiggly-line"/>
		<h2>Optimal transport</h2>

		<p>
			For optimal transport, sometimes called the <i>earth mover's distance</i> or <i>Wasserstein distance</i>, the underlying idea is to consider how much work it is to go from one distribution to another, both of the same mass. In the simplest case where the two distributions are point masses, this required work is equal to the distance between the two points. For more complex distributions $\mu, \nu : X \to \mathbb{R}$, a <i>transport plan</i> $\pi : X \times X \to \mathbb{R}$ tells us how much mass to move for each pair of points. In order to preserve mass, this means that for any point $y$, the mass of $\nu$ at $y$, $\nu(y)$, must match the mass which is moved from $X$ to $y$, i.e., $$\nu(y) = \int_X \pi(x,y)\,dx.$$ There can be many such transport plans but the optimal transport distance is the minimal <i>cost</i> $\int_{X \times Y} |x-y| \pi(x,y)\,dx\,dy$ over all possible transport plans. The concept is most easily demonstrated by an animation like in the following figure.
		</p>
		<div class="figure_container">
			<a data-fancybox="gallery3" href="media/08_ot_morph.mp4">
				<video class="figure" src="media/08_ot_morph.mp4" autoplay muted playsinline loop preload="metadata"></video>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Continuous morphing along straight lines for an optimal transport plan between two distributions. Dottiness is a consequence of numerical inexactness.
		</div>
		<p>
			There are extensions where we can punish distance nonlinearly or differently depending on the axis but for the purpose of this post we can think of it as the sum of all the distances moved multiplied by the mass moved at each point.
		</p>

		<hr class="squiggly-line"/>
		<h2>Optimal spectrogram transport</h2>

		<p>
			The <a href="https://en.wikipedia.org/wiki/Spectrogram">spectrogram</a> of a signal is a 2-dimensional representation, meaning a function $\mathbb{R} \times \mathbb{R} \to \mathbb{R}$, where the axes represent time and frequency. It should be thought of as a series of spectra (absolute value of Fourier transform) for small time snippets of the full signal, ordered in increasing time along the $x$-axis. In the following figure, we show an example of a spectrogram of a signal which changes its frequency contents over time to illustrate the concept. 
		</p>
		<div class="figure_container">
			<a data-fancybox="gallery4" href="media/10_spectrogram_showcase.png">
				<img class="figure" src="media/10_spectrogram_showcase.png"></img>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Signal and associated spectrogram for a signal which goes from steady tone to chirp to silence to two close tones.
		</div>

		<p>
			Now the idea behind optimal spectrogram transport is that the optimal transport distance between spectrograms should capture most of what we intuitively think of as distance between signals of this kind. Below we have chosen a slightly modified version of the above signal (different steady tone, reversed chirp, two tones moved and modulated) and illustrate the optimal transport interpolation between them. 
		</p>

		<div class="figure_container">
			<a data-fancybox="gallery5" href="media/10_ot_spectrogram_morph.mp4">
				<video class="figure" src="media/10_ot_spectrogram_morph.mp4" autoplay muted playsinline loop preload="metadata"></video>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Optimal transport morphing between spectrograms of two similar signals with slightly different characteristics.
		</div>

		<p>
			This is how we define optimal spectrogram transport distance. Note that there exists <a href="https://ott-jax.readthedocs.io/" target="_blank">fast algorithms and libraries</a> for computing optimal transport with GPU acceleration but even on a CPU this computation is feasible in a real-time setting.
		</p>
	
		<hr class="squiggly-line"/>
		<h2 id="examples">Examples</h2>

		<p>
			For all our examples, we will consider families of functions indexed by some continuous variable which intuitively should result in a continuously increasing distance. The first such example is for a modulated Gaussian, $f(x) = \sin(x) e^{-x^2}$, which we dilate using a dilation parameter $a$. A nice distance function should then satisfy
			$$
			d(f_{a_1}, f_{a_2}) \propto |a_1 - a_2|
			$$
			where we mean proportionality in a loose sense. In the figure below, we have signals and spectrograms for three such dilations and the continuous functions $d(f_a, f_1)$.
		</p>
		<div class="figure_container_small">
			<a data-fancybox="gallery6" href="media/02_gaussian_speed_warp.png">
				<img class="figure" src="media/02_gaussian_speed_warp.png"></img>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Euclidean $\ell^2$, dynamic time warping and optimal spectrogram distances for a family of modulated Guassians with varying dilations.
		</div>
		<p>
			In this case, Euclidean distance works okay for small dilations but plateaus for larger ones, while dynamic time warping is mostly flat. Meanwhile optimal spectrogram transport distance behaves like we want it to and continues increasing as the dilation parameter moves away from $1$.
		</p>

		<p>
			The GIF in the beginning of the post covered how the metric is continuous with respect to modulations. We compare continuity with respect to translations in the following example.
		</p>

		<div class="figure_container_small">
			<a data-fancybox="gallery6" href="media/03_gaussian_time_shift.png">
				<img class="figure" src="media/03_gaussian_time_shift.png"></img>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Euclidean $\ell^2$, dynamic time warping and optimal spectrogram distances for a family of modulated Gaussians with varying translation.
		</div>

		<p>
			Again, the behavior of optimal spectrogram transport is preferable to that of both Euclidean and dynamic time warping distance.
		</p>

		<p>
			Lastly we consider the case of continuity with respect to noise level which all the different metrics handle well.
		</p>

		<div class="figure_container_small">
			<a data-fancybox="gallery6" href="media/06_noise_robustness.png">
				<img class="figure" src="media/06_noise_robustness.png"></img>
			</a>
		</div>
		<div class="figure_caption">
			<span class="caption_title">Figure: </span> Euclidean $\ell^2$, dynamic time warping and optimal spectrogram distances for a family of modulated Gaussians with varying noise levels.
		</div>

		<hr class="squiggly-line"/>

		<p>
			Lorem ipsum dolor sit amet consectetur adipisicing elit. Alias unde iure enim vel, consectetur debitis reiciendis corrupti distinctio voluptatem expedita molestias necessitatibus amet, harum blanditiis ex earum tempora mollitia. Assumenda!
		</p>

	</section>
	
	<link rel="stylesheet" href="../fancybox.css" />
	<script src="../fancybox.umd.js"></script>

	<script>
		Fancybox.bind("[data-fancybox]", {
			closeButton: false,
		});
	  </script>


</body>
</html>